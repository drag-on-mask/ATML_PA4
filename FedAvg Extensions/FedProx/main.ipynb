{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FedProx Implementation (Assignment 4, Task 4.1)\n",
    "\n",
    "This notebook implements the **FedProx** algorithm as described in Task 4.1 of the assignment. \n",
    "\n",
    "**Goal:** Modify the client-side training (FedAvg) to include a proximal term. This term penalizes the local model for moving too far from the global model it received at the start of the round.\n",
    "\n",
    "The modified loss on the client is:\n",
    "\n",
    "$$L_{client} = L_{local} + \\frac{\\mu}{2} ||\\theta - \\theta_{g}^{t}||^2$$\n",
    "\n",
    "Where:\n",
    "* $L_{local}$ is the standard cross-entropy loss on the client's local data batch.\n",
    "* $\\mu$ (mu) is the regularization hyperparameter.\n",
    "* $\\theta$ (theta) represents the current local model parameters being trained.\n",
    "* $\\theta_{g}^{t}$ (theta_g_t) represents the global model parameters received from the server at the beginning of round $t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports\n",
    "\n",
    "Import all necessary libraries from PyTorch, torchvision, NumPy, and Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "import random\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hyperparameters and Device Setup\n",
    "\n",
    "We define all key hyperparameters here. To test FedProx's effectiveness, we set a high degree of heterogeneity (`alpha=0.1`) and a `mu=0.01` as suggested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "HYPERPARAMS = {\n",
    "    \"num_clients\": 5,          # 5-10 clients suggested \n",
    "    \"num_rounds\": 50,          # Total communication rounds\n",
    "    \"local_epochs\": 5,           # K=5 local epochs per round\n",
    "    \"batch_size\": 32,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"mu\": 0.01,                  # FedProx proximal term\n",
    "    \"dirichlet_alpha\": 0.1,      # For highly non-IID data (small alpha = high skew)\n",
    "    \"seed\": 42\n",
    "}\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(HYPERPARAMS['seed'])\n",
    "np.random.seed(HYPERPARAMS['seed'])\n",
    "random.seed(HYPERPARAMS['seed'])\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Definition (Simple CNN)\n",
    "\n",
    "As recommended, we use a small Convolutional Neural Network (CNN) suitable for CIFAR-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=800, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # Two conv layers as suggested \n",
    "        self.conv1 = nn.Conv2d(3, 16, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5)\n",
    "        # A small FC layer\n",
    "        self.fc1 = nn.Linear(32 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10) # 10 classes for CIFAR-10\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 32 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model_check = CNN().to(device)\n",
    "print(model_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Loading and Partitioning (Non-IID)\n",
    "\n",
    "This section contains helper functions to load CIFAR-10 and partition it among clients using a **Dirichlet distribution**, as specified in Task 3. This is necessary to create the non-IID scenario to test FedProx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cifar10_data():\n",
    "    \"\"\"Downloads CIFAR-10 train and test datasets.\"\"\"\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                            download=True, transform=transform)\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                           download=True, transform=transform)\n",
    "    return trainset, testset\n",
    "\n",
    "def dirichlet_partition_data(dataset, num_clients, alpha):\n",
    "    \"\"\"\n",
    "    Partitions data among clients using a Dirichlet distribution (for label skew).\n",
    "    Based on Task 3 instructions.\n",
    "    \"\"\"\n",
    "    labels = np.array(dataset.targets)\n",
    "    num_classes = len(np.unique(labels))\n",
    "    idx_by_class = {i: np.where(labels == i)[0] for i in range(num_classes)}\n",
    "\n",
    "    # Generate class proportions for each client from Dir(alpha)\n",
    "    # Each row is a client, each column is a class\n",
    "    class_proportions = np.random.dirichlet([alpha] * num_clients, num_classes)\n",
    "    \n",
    "    client_data_indices = {i: [] for i in range(num_clients)}\n",
    "    \n",
    "    # Keep track of how many samples of each class have been assigned\n",
    "    class_sample_counts = {i: len(idx_by_class[i]) for i in range(num_classes)}\n",
    "    class_sample_ptr = {i: 0 for i in range(num_classes)}\n",
    "\n",
    "    for c in range(num_classes):\n",
    "        class_indices = idx_by_class[c]\n",
    "        np.random.shuffle(class_indices)\n",
    "        \n",
    "        # Calculate how many samples each client gets for this class\n",
    "        proportions = class_proportions[c]\n",
    "        num_samples_for_class = class_sample_counts[c]\n",
    "        client_counts = (proportions * num_samples_for_class).astype(int)\n",
    "        \n",
    "        # Adjust counts to sum up to the total number of samples for the class\n",
    "        # (due to integer rounding)\n",
    "        diff = num_samples_for_class - client_counts.sum()\n",
    "        for i in range(diff):\n",
    "            client_counts[i % num_clients] += 1\n",
    "\n",
    "        start_idx = 0\n",
    "        for client_id in range(num_clients):\n",
    "            num_samples_for_client = client_counts[client_id]\n",
    "            end_idx = start_idx + num_samples_for_client\n",
    "            \n",
    "            client_data_indices[client_id].extend(class_indices[start_idx:end_idx])\n",
    "            start_idx = end_idx\n",
    "            \n",
    "    return client_data_indices\n",
    "\n",
    "class ClientDataset(Dataset):\n",
    "    \"\"\"A custom Dataset to wrap a subset of the main dataset.\"\"\"\n",
    "    def __init__(self, full_dataset, indices):\n",
    "        self.full_dataset = full_dataset\n",
    "        self.indices = indices\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.full_dataset[self.indices[idx]]\n",
    "\n",
    "def get_dataloaders(num_clients, alpha, batch_size):\n",
    "    \"\"\"Loads data, partitions it, and returns DataLoaders.\"\"\"\n",
    "    trainset, testset = get_cifar10_data()\n",
    "    \n",
    "    # Partition training data\n",
    "    client_indices = dirichlet_partition_data(trainset, num_clients, alpha)\n",
    "    \n",
    "    train_loaders = []\n",
    "    client_data_sizes = []\n",
    "    for i in range(num_clients):\n",
    "        dataset = ClientDataset(trainset, client_indices[i])\n",
    "        loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "        train_loaders.append(loader)\n",
    "        client_data_sizes.append(len(dataset))\n",
    "        \n",
    "    # Global test loader\n",
    "    test_loader = DataLoader(testset, batch_size=batch_size * 2, shuffle=False)\n",
    "    \n",
    "    total_data_size = sum(client_data_sizes)\n",
    "    client_weights = [size / total_data_size for size in client_data_sizes]\n",
    "    \n",
    "    return train_loaders, test_loader, client_weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. FedProx Client Update (Task 4.1)\n",
    "\n",
    "This is the **core function for Task 4.1**. \n",
    "\n",
    "It performs the local training for a client. It takes `mu` as an argument.\n",
    "* If `mu == 0`, this function performs a standard **FedAvg** update.\n",
    "* If `mu > 0`, it performs a **FedProx** update by calculating the proximal term and adding it to the loss before `loss.backward()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_train_fedprox(local_model, global_model, train_loader, local_epochs, lr, mu, device):\n",
    "    \"\"\"\n",
    "    Trains a client model locally with the FedProx objective.\n",
    "    Args:\n",
    "        local_model (nn.Module): The client's model (a deepcopy of the global model).\n",
    "        global_model (nn.Module): The global model from the server (used for prox term).\n",
    "        train_loader (DataLoader): The client's local data loader.\n",
    "        local_epochs (int): Number of local epochs (K).\n",
    "        lr (float): Learning rate.\n",
    "        mu (float): The proximal term coefficient.\n",
    "        device (torch.device): The device to train on (CPU or CUDA).\n",
    "    Returns:\n",
    "        dict: The state dictionary of the trained local model.\n",
    "    \"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(local_model.parameters(), lr=lr)\n",
    "    \n",
    "    # Store the fixed parameters of the global model received at the start of the round\n",
    "    # We use .parameters() which are tensors, and requires_grad=False is implicitly handled\n",
    "    # since global_model is not part of the computation graph for the optimizer.\n",
    "    global_params = list(global_model.parameters())\n",
    "    \n",
    "    local_model.train()\n",
    "    for epoch in range(local_epochs):\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # 1. Forward pass\n",
    "            output = local_model(data)\n",
    "            \n",
    "            # 2. Standard cross-entropy loss\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            # --- FEDPROX MODIFICATION ---\n",
    "            if mu > 0:\n",
    "                prox_term = 0.0\n",
    "                \n",
    "                # Iterate over the parameters of the local and global models\n",
    "                local_params = list(local_model.parameters())\n",
    "                \n",
    "                for i in range(len(global_params)):\n",
    "                    # Calculate the squared L2 norm of the difference\n",
    "                    prox_term += (local_params[i] - global_params[i]).pow(2).sum()\n",
    "                \n",
    "                # Add the proximal term to the loss \n",
    "                loss += (mu / 2) * prox_term\n",
    "            # --- END OF FEDPROX MODIFICATION ---\n",
    "            \n",
    "            # 3. Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    return local_model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Server Aggregation and Evaluation\n",
    "\n",
    "Standard functions for federated averaging (server-side) and global model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def server_aggregate_fedavg(global_model, local_models_states, client_weights):\n",
    "    \"\"\"\n",
    "    Aggregates local model states into the global model using weighted averaging (FedAvg).\n",
    "    \n",
    "    \"\"\"\n",
    "    global_state_dict = global_model.state_dict()\n",
    "    \n",
    "    # Zero out the global model's state dict\n",
    "    for key in global_state_dict:\n",
    "        global_state_dict[key] = torch.zeros_like(global_state_dict[key])\n",
    "\n",
    "    # Accumulate weighted local states\n",
    "    for i, local_state in enumerate(local_models_states):\n",
    "        weight = client_weights[i]\n",
    "        for key in global_state_dict:\n",
    "            global_state_dict[key] += local_state[key] * weight\n",
    "            \n",
    "    # Load the new averaged state into the global model\n",
    "    global_model.load_state_dict(global_state_dict)\n",
    "\n",
    "\n",
    "def evaluate(model, test_loader, device):\n",
    "    \"\"\"Evaluates the model's accuracy on the test set.\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Main Training Loop (FedAvg vs. FedProx)\n",
    "\n",
    "Here we run the full federated learning simulation.\n",
    "\n",
    "To satisfy the task requirements, we will run two experiments simultaneously:\n",
    "1.  **Baseline FedAvg:** Using our `client_train_fedprox` function with `mu=0`.\n",
    "2.  **FedProx:** Using `client_train_fedprox` with `mu=0.01`.\n",
    "\n",
    "This allows for a direct comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting simulation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [1:06:32<00:00, 42.7kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded for 5 clients.\n",
      "Client data weights: [0.205, 0.367, 0.171, 0.05, 0.207]\n",
      "\n",
      "--- Round 1 / 50 ---\n",
      "FedAvg Accuracy: 20.55%\n",
      "FedProx (mu=0.01) Accuracy: 22.28%\n",
      "\n",
      "--- Round 2 / 50 ---\n",
      "FedAvg Accuracy: 25.95%\n",
      "FedProx (mu=0.01) Accuracy: 25.28%\n",
      "\n",
      "--- Round 3 / 50 ---\n",
      "FedAvg Accuracy: 30.33%\n",
      "FedProx (mu=0.01) Accuracy: 33.83%\n",
      "\n",
      "--- Round 4 / 50 ---\n",
      "FedAvg Accuracy: 38.37%\n",
      "FedProx (mu=0.01) Accuracy: 36.39%\n",
      "\n",
      "--- Round 5 / 50 ---\n",
      "FedAvg Accuracy: 42.83%\n",
      "FedProx (mu=0.01) Accuracy: 43.83%\n",
      "\n",
      "--- Round 6 / 50 ---\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting simulation...\")\n",
    "\n",
    "# 1. Load and partition data\n",
    "train_loaders, test_loader, client_weights = get_dataloaders(\n",
    "    HYPERPARAMS['num_clients'],\n",
    "    HYPERPARAMS['dirichlet_alpha'],\n",
    "    HYPERPARAMS['batch_size']\n",
    ")\n",
    "print(f\"Data loaded for {HYPERPARAMS['num_clients']} clients.\")\n",
    "print(f\"Client data weights: {[round(w, 3) for w in client_weights]}\")\n",
    "\n",
    "# 2. Initialize models\n",
    "# We need two separate global models to track, starting from the same initialization\n",
    "base_model = CNN().to(device)\n",
    "global_model_fedavg = copy.deepcopy(base_model)\n",
    "global_model_fedprox = copy.deepcopy(base_model)\n",
    "\n",
    "# 3. Storage for results\n",
    "results = {\n",
    "    'fedavg': {'accuracy': []},\n",
    "    'fedprox': {'accuracy': []}\n",
    "}\n",
    "\n",
    "# 4. Run Federated Training\n",
    "for round_idx in range(HYPERPARAMS['num_rounds']):\n",
    "    print(f\"\\n--- Round {round_idx + 1} / {HYPERPARAMS['num_rounds']} ---\")\n",
    "    \n",
    "    local_states_fedavg = []\n",
    "    local_states_fedprox = []\n",
    "\n",
    "    # --- Client Training --- \n",
    "    for client_id in range(HYPERPARAMS['num_clients']):\n",
    "        # --- Run FedAvg (mu=0) ---\n",
    "        # Create a fresh local model from the current global FedAvg model\n",
    "        local_model_fedavg = copy.deepcopy(global_model_fedavg).to(device)\n",
    "        \n",
    "        # The global_model_fedavg is passed here *only* for the prox term calculation (which is 0)\n",
    "        trained_state_fedavg = client_train_fedprox(\n",
    "            local_model=local_model_fedavg,\n",
    "            global_model=global_model_fedavg, # Pass global model for prox term\n",
    "            train_loader=train_loaders[client_id],\n",
    "            local_epochs=HYPERPARAMS['local_epochs'],\n",
    "            lr=HYPERPARAMS['learning_rate'],\n",
    "            mu=0.0,  # mu=0 makes this standard FedAvg\n",
    "            device=device\n",
    "        )\n",
    "        local_states_fedavg.append(trained_state_fedavg)\n",
    "        \n",
    "        # --- Run FedProx (mu=0.01) ---\n",
    "        # Create a fresh local model from the current global FedProx model\n",
    "        local_model_fedprox = copy.deepcopy(global_model_fedprox).to(device)\n",
    "        \n",
    "        # The global_model_fedprox is passed to calculate the prox term against\n",
    "        trained_state_fedprox = client_train_fedprox(\n",
    "            local_model=local_model_fedprox,\n",
    "            global_model=global_model_fedprox, # Pass global model for prox term\n",
    "            train_loader=train_loaders[client_id],\n",
    "            local_epochs=HYPERPARAMS['local_epochs'],\n",
    "            lr=HYPERPARAMS['learning_rate'],\n",
    "            mu=HYPERPARAMS['mu'], # Use the defined mu\n",
    "            device=device\n",
    "        )\n",
    "        local_states_fedprox.append(trained_state_fedprox)\n",
    "        \n",
    "    # --- Server Aggregation & Evaluation --- \n",
    "    \n",
    "    # FedAvg\n",
    "    server_aggregate_fedavg(global_model_fedavg, local_states_fedavg, client_weights)\n",
    "    acc_fedavg = evaluate(global_model_fedavg, test_loader, device)\n",
    "    results['fedavg']['accuracy'].append(acc_fedavg)\n",
    "    \n",
    "    # FedProx\n",
    "    server_aggregate_fedavg(global_model_fedprox, local_states_fedprox, client_weights)\n",
    "    acc_fedprox = evaluate(global_model_fedprox, test_loader, device)\n",
    "    results['fedprox']['accuracy'].append(acc_fedprox)\n",
    "    \n",
    "    print(f\"FedAvg Accuracy: {acc_fedavg:.2f}%\")\n",
    "    print(f\"FedProx (mu={HYPERPARAMS['mu']}) Accuracy: {acc_fedprox:.2f}%\")\n",
    "\n",
    "print(\"\\n--- Simulation Finished ---\")\n",
    "print(f\"Final FedAvg Accuracy: {results['fedavg']['accuracy'][-1]:.2f}%\")\n",
    "print(f\"Final FedProx Accuracy: {results['fedprox']['accuracy'][-1]:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Plot Results\n",
    "\n",
    "This plot compares the global test accuracy per communication round for both FedAvg and FedProx, as required for the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "rounds = range(1, HYPERPARAMS['num_rounds'] + 1)\n",
    "\n",
    "# Plot FedAvg\n",
    "plt.plot(rounds, results['fedavg']['accuracy'], label=f\"FedAvg (mu=0.0)\", marker='o', linestyle='--')\n",
    "\n",
    "# Plot FedProx\n",
    "plt.plot(rounds, results['fedprox']['accuracy'], label=f\"FedProx (mu={HYPERPARAMS['mu']})\", marker='x', linestyle='-')\n",
    "\n",
    "plt.title(f\"FedAvg vs. FedProx on Non-IID CIFAR-10 (alpha={HYPERPARAMS['dirichlet_alpha']})\")\n",
    "plt.xlabel(\"Communication Rounds\")\n",
    "plt.ylabel(\"Global Test Accuracy (%)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Observations (for your report)\n",
    "\n",
    "As required by the prompt, you should now analyze the plot.\n",
    "\n",
    "* **Does FedProx help?** You will likely observe that the FedProx curve is more stable (less oscillation) and potentially converges to a higher final accuracy than the standard FedAvg baseline. This demonstrates its ability to mitigate the client drift caused by the highly non-IID data.\n",
    "* **What to report:** You can state your hyperparameters (e.g., `alpha=0.1`, `mu=0.01`, `K=5`) and report the final accuracy numbers. For example: \"Under a high-heterogeneity setting (Dirichlet $\\alpha=0.1$), FedAvg achieved a final accuracy of X%, while FedProx stabilized training and improved accuracy to Y%\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
