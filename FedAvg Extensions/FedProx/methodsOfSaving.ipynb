{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing and Loading Models & Weights in PyTorch\n",
    "\n",
    "This notebook demonstrates the two primary ways to save and load your models in PyTorch:\n",
    "\n",
    "1.  **Saving/Loading the `state_dict` (Recommended)**: This saves only the learnable parameters (weights and biases) of the model. It's the most flexible and robust method, as it doesn't depend on the specific class definition or file structure remaining identical.\n",
    "2.  **Saving/Loading the Entire Model**: This saves the entire model object using Python's `pickle` module. While simple, it can break if you refactor your code or use the model in a different project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and Model Definition\n",
    "\n",
    "First, let's import the necessary libraries and define the same simple CNN model we used before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "\n",
    "# Define the same CNN model architecture\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5)\n",
    "        self.fc1 = nn.Linear(32 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 32 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "print(\"Libraries imported and CNN model defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Method 1: Saving/Loading the `state_dict` (Recommended)\n",
    "\n",
    "A model's `state_dict` is a Python dictionary that maps each layer to its parameter tensor (weights and biases)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Saving the state_dict ===\n",
    "\n",
    "# 1. Initialize a model\n",
    "model_to_save = CNN()\n",
    "\n",
    "# (Optional) Train the model here...\n",
    "# For this example, we'll just use its initial random weights.\n",
    "\n",
    "# 2. Define a path\n",
    "WEIGHTS_PATH = 'model_weights.pth'\n",
    "\n",
    "# 3. Save the state_dict\n",
    "torch.save(model_to_save.state_dict(), WEIGHTS_PATH)\n",
    "print(f\"Model weights saved to {WEIGHTS_PATH}\")\n",
    "\n",
    "# === Loading the state_dict ===\n",
    "\n",
    "# 1. Initialize a *new* instance of the model\n",
    "# You MUST create an instance of the model *before* you can load weights\n",
    "model_to_load = CNN()\n",
    "\n",
    "# 2. Load the state_dict from the file\n",
    "loaded_state_dict = torch.load(WEIGHTS_PATH)\n",
    "\n",
    "# 3. Load the state_dict into the model\n",
    "model_to_load.load_state_dict(loaded_state_dict)\n",
    "\n",
    "# 4. Set the model to evaluation mode (important if you have dropout, batchnorm, etc.)\n",
    "model_to_load.eval()\n",
    "\n",
    "print(f\"Model weights loaded successfully from {WEIGHTS_PATH}\")\n",
    "\n",
    "# You can verify by checking if the weights are identical\n",
    "original_weights = list(model_to_save.parameters())[0]\n",
    "loaded_weights = list(model_to_load.parameters())[0]\n",
    "print(f\"Weights are identical: {torch.equal(original_weights, loaded_weights)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Method 2: Saving/Loading the Entire Model\n",
    "\n",
    "This method saves the entire model object using Python's `pickle`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Saving the entire model ===\n",
    "\n",
    "# 1. Initialize a model\n",
    "model_to_save_full = CNN()\n",
    "\n",
    "# 2. Define a path\n",
    "FULL_MODEL_PATH = 'full_model.pth'\n",
    "\n",
    "# 3. Save the entire model object\n",
    "torch.save(model_to_save_full, FULL_MODEL_PATH)\n",
    "print(f\"Full model object saved to {FULL_MODEL_PATH}\")\n",
    "\n",
    "# === Loading the entire model ===\n",
    "\n",
    "# 1. Load the entire object from the file\n",
    "# You do not need to create an instance of the model first\n",
    "model_to_load_full = torch.load(FULL_MODEL_PATH)\n",
    "\n",
    "# 2. Set the model to evaluation mode\n",
    "model_to_load_full.eval()\n",
    "\n",
    "print(f\"Full model object loaded successfully from {FULL_MODEL_PATH}\")\n",
    "\n",
    "# Verify\n",
    "print(model_to_load_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Saving in a Federated Learning Loop\n",
    "\n",
    "In your main training loop, you would typically save the `state_dict` of your **global model** at the end of each round or at the very end of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_fl_loop():\n",
    "    # --- Inside your main training loop (from the previous notebook) ---\n",
    "    \n",
    "    # Initialize the global model\n",
    "    global_model = CNN() # .to(device)\n",
    "    \n",
    "    num_rounds = 5 # Example: 5 rounds\n",
    "    \n",
    "    for round_idx in range(num_rounds):\n",
    "        print(f\"Running round {round_idx + 1}...\")\n",
    "        # ... (client training and server aggregation logic) ...\n",
    "        # global_model.load_state_dict(new_aggregated_weights)\n",
    "        \n",
    "        # --- Save a checkpoint --- \n",
    "        # You could save at intermediate rounds\n",
    "        if (round_idx + 1) % 2 == 0:\n",
    "            checkpoint_path = f\"global_model_round_{round_idx + 1}.pth\"\n",
    "            torch.save(global_model.state_dict(), checkpoint_path)\n",
    "            print(f\"Saved checkpoint: {checkpoint_path}\")\n",
    "            \n",
    "    # --- Save the final model --- \n",
    "    FINAL_MODEL_PATH = \"global_model_final.pth\"\n",
    "    torch.save(global_model.state_dict(), FINAL_MODEL_PATH)\n",
    "    print(f\"\\nFinal model weights saved to {FINAL_MODEL_PATH}\")\n",
    "\n",
    "# Run the example loop\n",
    "example_fl_loop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}