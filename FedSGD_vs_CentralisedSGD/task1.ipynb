{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìã ATML PA4 - Task 1: FedSGD vs. Centralized SGD Equivalence\n",
    "\n",
    "**Goal:** Demonstrate that FedSGD (with full-batch gradients) is mathematically equivalent to centralized SGD.\n",
    "\n",
    "**McMahan's FedSGD:** Each client computes the gradient on its **entire local dataset** (which they denote as `B=‚àû`, or full-batch), and then the server averages these gradients (which is equivalent to averaging the models after one step with the same LR).\n",
    "\n",
    "We will compare this to a centralized model trained for the same number of steps, where each step is also a full-batch gradient computation over the **entire global dataset**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 1: Environment Setup**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.1. Imports and Configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üì¶ Imports and Environment Setup\n",
    "# ============================================\n",
    "import copy\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "# Add path to federated_learning.py\n",
    "# (Assuming this notebook is in a subdir and FedAvg is at ../FedAvg)\n",
    "fed_avg_path = os.path.abspath(os.path.join(os.getcwd(), \"../FedAvg\"))\n",
    "if fed_avg_path not in sys.path:\n",
    "    print(f\"Adding path: {fed_avg_path}\")\n",
    "    sys.path.append(fed_avg_path)\n",
    "\n",
    "try:\n",
    "    # We only need these specific components for this task\n",
    "    from federated_learning import SimpleCNN, aggregate_models, evaluate_model\n",
    "\n",
    "    print(\"Successfully imported from federated_learning module.\")\n",
    "except ImportError:\n",
    "    print(f\"Error: 'federated_learning.py' not found in path: {fed_avg_path}\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ============================================\n",
    "# ‚öôÔ∏è Main Configuration\n",
    "# ============================================\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "NUM_CLIENTS = 6\n",
    "NUM_ROUNDS = 50  # FedSGD rounds / Centralized steps\n",
    "LEARNING_RATE = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.2. Directory and Experiment Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üìÇ Directory and Experiment Setup\n",
    "# ============================================\n",
    "\n",
    "# Set to True to force re-training even if results.json exists\n",
    "RETRAIN_TASK1 = True \n",
    "\n",
    "# Define directories\n",
    "PLOT_DIR = 'plots/task1'\n",
    "JSON_DIR = 'json_results/task1'\n",
    "MODEL_DIR = 'pth_models/task1'\n",
    "\n",
    "os.makedirs(PLOT_DIR, exist_ok=True)\n",
    "os.makedirs(JSON_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "# Define file paths\n",
    "json_path = os.path.join(JSON_DIR, 'task1_results.json')\n",
    "fedsgd_model_path = os.path.join(MODEL_DIR, 'task1_fedsgd_model.pth')\n",
    "central_model_path = os.path.join(MODEL_DIR, 'task1_centralized_model.pth')\n",
    "\n",
    "print(f\"JSON results will be saved to: {json_path}\")\n",
    "print(f\"Models will be saved to: {MODEL_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 2: Data Loading (Full-Batch Setup)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.1. Load and Split CIFAR-10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üíæ Load CIFAR-10 and Split IID\n",
    "# ============================================\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=True, download=True, transform=transform_train\n",
    ")\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=False, download=True, transform=transform_test\n",
    ")\n",
    "\n",
    "# Split training data IID across clients\n",
    "total_size = len(train_dataset)\n",
    "indices = np.random.permutation(total_size)\n",
    "split_size = total_size // NUM_CLIENTS\n",
    "\n",
    "client_datasets = []\n",
    "client_sizes = []\n",
    "\n",
    "for i in range(NUM_CLIENTS):\n",
    "    start_idx = i * split_size\n",
    "    end_idx = (i + 1) * split_size if i < NUM_CLIENTS - 1 else total_size\n",
    "    client_indices = indices[start_idx:end_idx]\n",
    "    client_subset = Subset(train_dataset, client_indices)\n",
    "    client_datasets.append(client_subset)\n",
    "    client_sizes.append(len(client_indices))\n",
    "\n",
    "print(f\"Split data across {NUM_CLIENTS} clients\")\n",
    "print(f\"Client sizes: {client_sizes}\")\n",
    "print(f\"Total training samples: {sum(client_sizes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.2. Create Full-Batch Data Loaders**\n",
    "\n",
    "This is the key to simulating FedSGD. We create data loaders where the `batch_size` is set to the *entire length* of the client's dataset. This means that when we iterate on the loader, the first (and only) batch contains all of that client's data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üöö Create FULL-BATCH Data Loaders\n",
    "# ============================================\n",
    "\n",
    "# KEY: Set batch_size = entire client dataset!\n",
    "fedsgd_loaders = []\n",
    "for client_data in client_datasets:\n",
    "    # batch_size = len(dataset) ‚Üí 1 batch = entire data\n",
    "    loader = DataLoader(\n",
    "        client_data,\n",
    "        batch_size=len(client_data),  # ‚Üê FULL BATCH!\n",
    "        shuffle=True,\n",
    "        num_workers=2\n",
    "    )\n",
    "    fedsgd_loaders.append(loader)\n",
    "\n",
    "print(f\"Created {len(fedsgd_loaders)} full-batch data loaders for FedSGD.\")\n",
    "\n",
    "# Global test loader (standard mini-batch)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 3: Define Training Functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.1. FedSGD (McMahan Style)**\n",
    "\n",
    "We define a custom `fedsgd_client_update` function that performs *exactly one* gradient step using the full-batch loader. We also create a `run_fedsgd` orchestrator that mimics the federated training loop (distribute, update, aggregate, evaluate) but calls our custom update function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üíª FedSGD Implementation (McMahan Style)\n",
    "# ============================================\n",
    "\n",
    "def fedsgd_client_update(model, full_batch_loader, lr, device):\n",
    "    \"\"\"\n",
    "    McMahan's FedSGD: Compute gradient on ENTIRE local dataset.\n",
    "    \n",
    "    Since loader has batch_size=full_data, first batch = all data.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    # Use the same optimizer settings as in federated_learning.py for consistency\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Get the single full-batch\n",
    "    try:\n",
    "        data, target = next(iter(full_batch_loader))\n",
    "    except StopIteration:\n",
    "        print(\"Warning: Client data loader was empty.\")\n",
    "        return model.state_dict() # Return unchanged parameters\n",
    "        \n",
    "    data, target = data.to(device), target.to(device)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    output = model(data)\n",
    "    loss = criterion(output, target)\n",
    "    loss.backward() # Compute gradient\n",
    "    optimizer.step()  # Apply gradient step\n",
    "    \n",
    "    return model.state_dict()\n",
    "\n",
    "\n",
    "def run_fedsgd(num_clients, num_rounds, lr, device, seed=42):\n",
    "    \"\"\"\n",
    "    Run FedSGD for specified rounds.\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    global_model = SimpleCNN().to(device)\n",
    "    \n",
    "    history = {\n",
    "        \"test_acc\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"rounds\": []\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üöÄ Running FedSGD (Full-Batch)\")\n",
    "    print(f\"  Clients: {num_clients}\")\n",
    "    print(f\"  Rounds: {num_rounds}\")\n",
    "    print(f\"  Learning Rate: {lr}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    for round_idx in range(num_rounds):\n",
    "        # All clients participate (C=1.0)\n",
    "        client_models_params = []\n",
    "        client_weights = []\n",
    "        \n",
    "        global_params = copy.deepcopy(global_model.state_dict())\n",
    "        \n",
    "        for client_idx in range(num_clients):\n",
    "            # Create local model\n",
    "            local_model = SimpleCNN()\n",
    "            local_model.load_state_dict(global_params)\n",
    "            \n",
    "            # Full-batch gradient computation & step\n",
    "            updated_params = fedsgd_client_update(\n",
    "                local_model,\n",
    "                fedsgd_loaders[client_idx],\n",
    "                lr=lr,\n",
    "                device=device\n",
    "            )\n",
    "            \n",
    "            client_models_params.append(updated_params)\n",
    "            client_weights.append(client_sizes[client_idx])\n",
    "        \n",
    "        # Normalize weights\n",
    "        total_weight = sum(client_weights)\n",
    "        normalized_weights = [w / total_weight for w in client_weights]\n",
    "        \n",
    "        # Aggregate (using the function from our .py file)\n",
    "        aggregated_params = aggregate_models(client_models_params, normalized_weights)\n",
    "        global_model.load_state_dict(aggregated_params)\n",
    "        \n",
    "        # Evaluate (using the function from our .py file)\n",
    "        test_acc, test_loss = evaluate_model(global_model, test_loader, device)\n",
    "        \n",
    "        history['test_acc'].append(test_acc)\n",
    "        history['test_loss'].append(test_loss)\n",
    "        history['rounds'].append(round_idx + 1)\n",
    "        \n",
    "        if (round_idx + 1) % 10 == 0 or round_idx == 0:\n",
    "            print(f\"Round {round_idx + 1:2d}/{num_rounds} | \"\n",
    "                  f\"Test Acc: {test_acc:6.2f}% | Test Loss: {test_loss:.4f}\")\n",
    "    \n",
    "    print(f\"\\n--- FedSGD Training Complete ---\")\n",
    "    print(f\"Final Accuracy: {history['test_acc'][-1]:.2f}%\")\n",
    "    return global_model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.2. Centralized SGD (Full-Batch)**\n",
    "\n",
    "Now we define the centralized equivalent. We concatenate all client datasets into one large global dataset and create a *single* full-batch loader. We then run SGD for the same number of steps as the FedSGD rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üíª Centralized Training (Full-Batch)\n",
    "# ============================================\n",
    "\n",
    "def run_centralized(num_steps, lr, device, seed=42):\n",
    "    \"\"\"\n",
    "    Centralized training with full-batch gradient on ALL data.\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    model = SimpleCNN().to(device)\n",
    "    \n",
    "    # Combine all training data\n",
    "    combined_dataset = torch.utils.data.ConcatDataset(client_datasets)\n",
    "    \n",
    "    # Full-batch loader (entire 50k samples!)\n",
    "    full_loader = DataLoader(\n",
    "        combined_dataset,\n",
    "        batch_size=len(combined_dataset),  # ‚Üê ALL DATA\n",
    "        shuffle=True,\n",
    "        num_workers=2\n",
    "    )\n",
    "    \n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    history = {\n",
    "        \"test_acc\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"rounds\": []\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üöÄ Running Centralized SGD (Full-Batch)\")\n",
    "    print(f\"  Steps: {num_steps}\")\n",
    "    print(f\"  Learning Rate: {lr}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        model.train()\n",
    "        \n",
    "        # Get full batch\n",
    "        try:\n",
    "            data, target = next(iter(full_loader))\n",
    "        except StopIteration:\n",
    "            print(\"Error: Centralized loader was empty.\")\n",
    "            break\n",
    "            \n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Evaluate\n",
    "        test_acc, test_loss = evaluate_model(model, test_loader, device)\n",
    "        \n",
    "        history['test_acc'].append(test_acc)\n",
    "        history['test_loss'].append(test_loss)\n",
    "        history['rounds'].append(step + 1)\n",
    "        \n",
    "        if (step + 1) % 10 == 0 or step == 0:\n",
    "            print(f\"Step {step + 1:2d}/{num_steps} | \"\n",
    "                  f\"Test Acc: {test_acc:6.2f}% | Test Loss: {test_loss:.4f}\")\n",
    "    \n",
    "    print(f\"\\n--- Centralized Training Complete ---\")\n",
    "    print(f\"Final Accuracy: {history['test_acc'][-1]:.2f}%\")\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 4: Execute Training**\n",
    "\n",
    "We now run both functions. If `task1_results.json` exists and `RETRAIN_TASK1` is `False`, we will skip this and load the results directly from the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üöÄ Run Experiment (or Load Results)\n",
    "# ============================================\n",
    "\n",
    "if not os.path.exists(json_path) or RETRAIN_TASK1:\n",
    "    print(f\"Running training for Task 1...\")\n",
    "    \n",
    "    # Run FedSGD\n",
    "    fedsgd_model, fedsgd_history = run_fedsgd(\n",
    "        num_clients=NUM_CLIENTS,\n",
    "        num_rounds=NUM_ROUNDS,\n",
    "        lr=LEARNING_RATE,\n",
    "        device=device,\n",
    "        seed=SEED\n",
    "    )\n",
    "\n",
    "    # Run Centralized (same number of steps)\n",
    "    centralized_model, centralized_history = run_centralized(\n",
    "        num_steps=NUM_ROUNDS,\n",
    "        lr=LEARNING_RATE,\n",
    "        device=device,\n",
    "        seed=SEED\n",
    "    )\n",
    "    \n",
    "    # --- Save Models ---\n",
    "    print(f\"\\nSaving models to {MODEL_DIR}...\")\n",
    "    torch.save(fedsgd_model.state_dict(), fedsgd_model_path)\n",
    "    torch.save(centralized_model.state_dict(), central_model_path)\n",
    "\n",
    "    # --- Calculate Weight Difference ---\n",
    "    print(\"Calculating weight differences...\")\n",
    "    fedsgd_params = fedsgd_model.state_dict()\n",
    "    central_params = centralized_model.state_dict()\n",
    "    per_layer_diff = {}\n",
    "    total_diff = 0\n",
    "    for key in fedsgd_params.keys():\n",
    "        diff = torch.norm(fedsgd_params[key].cpu() - central_params[key].cpu()).item()\n",
    "        per_layer_diff[key] = diff\n",
    "        total_diff += diff\n",
    "    \n",
    "    # --- Save Results to JSON ---\n",
    "    results = {\n",
    "        \"fedsgd\": fedsgd_history,\n",
    "        \"centralized\": centralized_history,\n",
    "        \"weight_difference_total\": total_diff,\n",
    "        \"weight_difference_per_layer\": per_layer_diff\n",
    "    }\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "    print(f\"Saved results to {json_path}\")\n",
    "\n",
    "else:\n",
    "    print(f\"Loading existing results from {json_path}\")\n",
    "    with open(json_path, 'r') as f:\n",
    "        results = json.load(f)\n",
    "    \n",
    "    fedsgd_history = results['fedsgd']\n",
    "    centralized_history = results['centralized']\n",
    "    total_diff = results['weight_difference_total']\n",
    "    print(\"...Load complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 5: Analysis and Plotting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.1. Accuracy Comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üìà Compare Final Results\n",
    "# ============================================\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Comparison (After {NUM_ROUNDS} Rounds/Steps)\")\n",
    "print(f\"{'='*70}\")\n",
    "fedsgd_final_acc = fedsgd_history['test_acc'][-1]\n",
    "central_final_acc = centralized_history['test_acc'][-1]\n",
    "\n",
    "print(f\"FedSGD Final Accuracy:       {fedsgd_final_acc:10.6f}%\")\n",
    "print(f\"Centralized Final Accuracy:  {central_final_acc:10.6f}%\")\n",
    "print(f\"----------------------------------------------\")\n",
    "print(f\"Absolute Difference:         {abs(fedsgd_final_acc - central_final_acc):10.6f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.2. Plotting**\n",
    "\n",
    "We plot the accuracy and loss curves over time. We expect them to be nearly identical, proving the equivalence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üìä Plot Comparison\n",
    "# ============================================\n",
    "plot_path = os.path.join(PLOT_DIR, 'task1_fedsgd_vs_centralized.png')\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.suptitle('Task 1: FedSGD vs Centralized (Full-Batch Equivalence)', fontsize=16, y=1.02)\n",
    "\n",
    "# Accuracy\n",
    "axes[0].plot(fedsgd_history['rounds'], fedsgd_history['test_acc'], \n",
    "             label='FedSGD', marker='o', markersize=4, alpha=0.8)\n",
    "axes[0].plot(centralized_history['rounds'], centralized_history['test_acc'], \n",
    "             label='Centralized', marker='s', markersize=4, linestyle='--', alpha=0.8)\n",
    "axes[0].set_xlabel('Round/Step')\n",
    "axes[0].set_ylabel('Test Accuracy (%)')\n",
    "axes[0].set_title('Test Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# Loss\n",
    "axes[1].plot(fedsgd_history['rounds'], fedsgd_history['test_loss'], \n",
    "             label='FedSGD', marker='o', markersize=4, alpha=0.8)\n",
    "axes[1].plot(centralized_history['rounds'], centralized_history['test_loss'], \n",
    "             label='Centralized', marker='s', markersize=4, linestyle='--', alpha=0.8)\n",
    "axes[1].set_xlabel('Round/Step')\n",
    "axes[1].set_ylabel('Test Loss')\n",
    "axes[1].set_title('Test Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"Saved plot to {plot_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.3. Model Weight Difference Analysis**\n",
    "\n",
    "Finally, we load the saved models (if they aren't already in memory) and compute the L2 norm of the difference between their parameters. If the methods are truly equivalent, this difference should be extremely close to zero (e.g., `< 1e-5`), accounting for floating-point arithmetic variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üî¨ Weight Difference Analysis\n",
    "# ============================================\n",
    "\n",
    "# If we didn't train, load the models from disk for analysis\n",
    "if 'fedsgd_model' not in locals() or 'centralized_model' not in locals():\n",
    "    print(\"Loading models from disk for weight comparison...\")\n",
    "    try:\n",
    "        fedsgd_model = SimpleCNN()\n",
    "        fedsgd_model.load_state_dict(torch.load(fedsgd_model_path, map_location=device))\n",
    "        fedsgd_model.to(device)\n",
    "        \n",
    "        centralized_model = SimpleCNN()\n",
    "        centralized_model.load_state_dict(torch.load(central_model_path, map_location=device))\n",
    "        centralized_model.to(device)\n",
    "        print(\"...Models loaded.\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: Model files not found. Please run training first by setting RETRAIN_TASK1 = True.\")\n",
    "        fedsgd_model = None # Set to None to skip analysis\n",
    "\n",
    "if fedsgd_model is not None:\n",
    "    # Compare final model weights\n",
    "    fedsgd_params = fedsgd_model.state_dict()\n",
    "    central_params = centralized_model.state_dict()\n",
    "\n",
    "    per_layer_diffs_loaded = {}\n",
    "    total_diff_loaded = 0\n",
    "    \n",
    "    print(\"\\nPer-Layer L2 Norm Difference:\")\n",
    "    for key in fedsgd_params.keys():\n",
    "        diff = torch.norm(fedsgd_params[key] - central_params[key]).item()\n",
    "        per_layer_diffs_loaded[key] = diff\n",
    "        total_diff_loaded += diff\n",
    "        print(f\"  {key:20s}: L2 diff = {diff:.8e}\")\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Total L2 difference between model weights: {total_diff_loaded:.8e}\")\n",
    "    \n",
    "    # Final verdict\n",
    "    # (Floating point errors can accumulate, so we check against a small epsilon)\n",
    "    if total_diff_loaded < 1e-4:\n",
    "        print(\"‚úÖ Equivalence PROVEN. The models are mathematically identical within floating-point error.\")\n",
    "    else:\n",
    "        print(f\"‚ùå Models are not equivalent. Total difference ({total_diff_loaded:.8e}) is larger than expected.\")\n",
    "else:\n",
    "    print(\"\\nSkipping weight analysis as models could not be loaded.\")\n",
    "\n",
    "print(\"\\n‚úÖ Task 1 complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
